{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM8iMrAZm0uXqYwLIe6SqVJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"2twpWGhj4niu"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q42IpXQn4i-r","executionInfo":{"status":"ok","timestamp":1667670116762,"user_tz":420,"elapsed":20615,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"cb241185-5d65-4c99-8d6b-698ea863524f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/cs230"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGPKB6RM36sA","executionInfo":{"status":"ok","timestamp":1667670138267,"user_tz":420,"elapsed":167,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"f5bbc291-80b0-4823-f2d9-f41e238bdb15"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/cs230\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhRbwxCX4upk","executionInfo":{"status":"ok","timestamp":1667670220600,"user_tz":420,"elapsed":202,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"07e606eb-e393-4f70-b661-e786e8441fe5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   sustainbench/sustainbench/download_datasets.py\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\n","\t\u001b[31msetup.ipynb\u001b[m\n","\t\u001b[31msustainbench/dhs/\u001b[m\n","\t\u001b[31mwomens_edu/\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git add setup.ipynb womens_edu/"],"metadata":{"id":"rUV_9wAB5ChF","executionInfo":{"status":"ok","timestamp":1667670225644,"user_tz":420,"elapsed":178,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAdxgxswDk3C"},"outputs":[],"source":["import argparse\n","import logging\n","import os\n","\n","import h5py\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models\n","from torchvision import transforms, utils\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","from skimage import io, transform\n","from sklearn.metrics import r2_score"]},{"cell_type":"code","source":["if not os.path.exists(args.save_name):\n","    os.makedirs(args.save_name)\n","logging.basicConfig(filename=args.save_name + '/log', level=logging.DEBUG)\n","writer = SummaryWriter(args.save_name)"],"metadata":{"id":"hwADCdB4EBUi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ImgDataset"],"metadata":{"id":"UofYCz3YECx6"}},{"cell_type":"code","source":["class ImgDataset(Dataset):\n","    def __init__(self, df, device):\n","        self.img_paths = df['img_path_224x224'].to_numpy()\n","        self.targets = df[args.label].to_numpy()\n","        self.device = device\n","\n","    def __len__(self):\n","        return self.img_paths.shape[0]\n","\n","    def __getitem__(self, idx):\n","        image = io.imread(self.img_paths[idx])\n","        image_tensor = torch.from_numpy(image)\n","        image_tensor = image_tensor.permute(2,0,1).float()\n","        target = torch.Tensor(np.array([self.targets[idx]]))\n","        return image_tensor, target"],"metadata":{"id":"MwW9SyTtD9Tl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model "],"metadata":{"id":"jAc6tdNdET5R"}},{"cell_type":"code","source":["def create_model():\n","    if args.model == 'resnet18':\n","        model = models.resnet18(pretrained=args.pretrained)\n","    elif args.model == 'resnet34':\n","        model = models.resnet34(pretrained=args.pretrained)\n","    model.fc = nn.Sequential(nn.Linear(512, 1), nn.Tanh())\n","    return model"],"metadata":{"id":"0oTaMgzJEFyP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, device, train_loader, optimizer, criterion, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        target = target.cpu().detach().numpy()\n","        pred = output.cpu().detach().numpy()\n","        r2 = r2_score(target, pred)\n","        \n","        if batch_idx % 5 == 0:\n","            logging.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tR2: {:.4f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item(), \n","                r2))\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tR2: {:.4f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item(), \n","                r2))\n","            writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + batch_idx)\n","            writer.add_scalar('R2/train', r2, epoch * len(train_loader) + batch_idx)"],"metadata":{"id":"jLAv3313EJmT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, device, test_loader, criterion, epoch):\n","    model.eval()\n","    test_loss = 0\n","    total = 0\n","    y_true = np.array([])\n","    y_pred = np.array([])\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            total += target.size(0)\n","            output = model(data)\n","            target = target.cpu().detach().numpy().squeeze()\n","            pred = output.cpu().detach().numpy().squeeze()\n","            y_true = np.append(y_true, target)\n","            y_pred = np.append(y_pred, pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    logging.info('\\nTest set: R2: {:.4f}\\n'.format(r2)) \n","    print('\\nTest set: R2: {:.4f}\\n'.format(r2))\n","    writer.add_scalar('R2/test', r2, epoch * total)\n","    return r2, y_true, y_pred"],"metadata":{"id":"bcS-181EEJK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    print('Getting the clusters')\n","    train_f = open('train_clusters_ia.txt', 'r')\n","    val_f = open('val_clusters_ia.txt', 'r')\n","    train_clusters = [x[:-1] for x in train_f.readlines()]\n","    val_clusters = [x[:-1] for x in val_f.readlines()]\n","    train_f.close()\n","    val_f.close()\n","\n","    print('Preparing the dataloader')\n","    df = pd.read_csv('data.csv')\n","    train_df = df.loc[df['unique_cluster'].isin(train_clusters)]\n","    train_df = train_df.sample(frac=1).reset_index(drop=True)\n","    val_df = df.loc[df['unique_cluster'].isin(val_clusters)]\n","    val_df = val_df.sample(frac=1).reset_index(drop=True)\n","\n","    train_dataset = ImgDataset(train_df, device)\n","    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=2)\n","    val_dataset = ImgDataset(val_df, device)\n","    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=2)\n","\n","    model = create_model().to(device)\n","    criterion = torch.nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-6)\n","\n","    if not args.eval_mode:\n","        print('Starting training')\n","        best_r2 = 0.\n","        for epoch in range(1, args.num_epochs+1):\n","            train(model, device, train_loader, optimizer, criterion, epoch)\n","            r2, y_true, y_pred = test(model, device, val_loader, criterion, epoch)\n","            if r2 >= best_r2:\n","                best_r2 = r2\n","                torch.save(model.state_dict(), args.save_name + \"/model\")\n","                logging.info(\"\\nSaved model with R2: {:.4f}\\n\".format(best_r2))\n","        \n","        logging.info(\"\\nBest R2: {:.4f}\\n\".format(best_r2))\n","        print(\"\\nBest R2: {:.4f}\\n\".format(best_r2))\n","    else:\n","        r2, y_true, y_pred = test(model, device, val_loader, criterion, 1)\n","        print(\"\\nVal R2: {:.4f}\\n\".format(best_r2))\n","\n","    # Saves the predictions\n","    df = pd.DataFrame({'unique_cluster': val_clusters,\n","                   args.label: y_true,\n","                   args.label + 'pred': y_pred})\n","    df.to_csv(args.save_name + '/' + args.label + '_preds.csv', index=False)"],"metadata":{"id":"g1WALAarEX6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Main"],"metadata":{"id":"ZxwZYd3EEYWj"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main() \n"],"metadata":{"id":"MfNV2bvLEZAm"},"execution_count":null,"outputs":[]}]}