{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["zDrgLqlQbUUR"],"authorship_tag":"ABX9TyOuDmNZWAqnroOWAABqGkSs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtEzs3dSaSYZ","executionInfo":{"status":"ok","timestamp":1669951044457,"user_tz":480,"elapsed":31211,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"e2981cc3-3c09-46f7-e2f3-fbf3c9d91e90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/cs230/womens_edu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_v0i2laGayPd","executionInfo":{"status":"ok","timestamp":1669951046303,"user_tz":480,"elapsed":1851,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"a247092b-e31d-4c08-bb0d-2d0e69c5dd55"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu\n"]}]},{"cell_type":"code","source":["import argparse\n","import logging\n","import os\n","\n","import h5py\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models\n","from torchvision import transforms, utils\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","from skimage import io, transform\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error"],"metadata":{"id":"ru_XmlQDa17B","executionInfo":{"status":"ok","timestamp":1669951050188,"user_tz":480,"elapsed":3890,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["dataset_root_dir = '/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu/data/'"],"metadata":{"id":"ko_lpQBEa5dP","executionInfo":{"status":"ok","timestamp":1669951050189,"user_tz":480,"elapsed":9,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def split_train_val_test(df, train_yr, val_yr, test_yr):\n","  df['year'] = pd.to_numeric(df['year'])\n","  df = df.sample(frac=1, random_state=1234)\n","\n","  train_df = df[ df['year'] <= train_yr  ]\n","  val_df = df[ (df['year'] > train_yr) & (df['year'] <= val_yr) ]\n","  test_df = df[ (df['year'] > val_yr) & (df['year'] <= test_yr) ]\n","  return train_df, val_df, test_df "],"metadata":{"id":"9G3NajicdO3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"disaaldan@gmail.com\"\n","!git config --global user.name \"disaalda\""],"metadata":{"id":"XMfPMgaH1nxi","executionInfo":{"status":"ok","timestamp":1669951052213,"user_tz":480,"elapsed":2030,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"id":"lithLEmz1qaT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Processing "],"metadata":{"id":"r9RfKqCIljld"}},{"cell_type":"code","source":["df = pd.read_csv('data/filtered_sampled_ss.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"a9ALmpszliUN","executionInfo":{"status":"ok","timestamp":1669915954645,"user_tz":480,"elapsed":1725,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"ffdffc04-90af-4186-fd3a-7442a4f09547"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  Unnamed: 1  Unnamed: 0.1             DHSID_EA  year  cc  \\\n","0           0       74101         74101  AM-2010-6#-00000175  2010  AM   \n","1           1       74102         74102  AM-2010-6#-00000176  2010  AM   \n","2           2       74103         74103  AM-2010-6#-00000215  2010  AM   \n","3           3       74104         74104  AM-2010-6#-00000218  2010  AM   \n","4           4       74105         74105  AM-2010-6#-00000232  2010  AM   \n","\n","         lat        lon  women_edu  \\\n","0  40.865949  44.052637  10.307692   \n","1  40.878055  44.042707  10.761905   \n","2  40.776914  43.841243  12.476190   \n","3  40.808131  43.840526  12.600000   \n","4  40.765091  43.783366  11.480000   \n","\n","                                                path  img_captured_at  \\\n","0  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1341142789364   \n","1  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1341142789364   \n","2  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1295470496500   \n","3  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1295470496500   \n","4  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1295470496500   \n","\n","     img_lon    img_lat           img_id  \\\n","0  44.118895  40.914849  455621522386245   \n","1  44.118895  40.914849  455621522386245   \n","2  43.853536  40.802320  448238129596253   \n","3  43.852432  40.798289  803317710311828   \n","4  43.853536  40.802320  448238129596253   \n","\n","                                      img_path  \n","0  AM/AM-2010-6#-00000175/455621522386245.jpeg  \n","1  AM/AM-2010-6#-00000176/455621522386245.jpeg  \n","2  AM/AM-2010-6#-00000215/448238129596253.jpeg  \n","3  AM/AM-2010-6#-00000218/803317710311828.jpeg  \n","4  AM/AM-2010-6#-00000232/448238129596253.jpeg  "],"text/html":["\n","  <div id=\"df-5aee304d-d80c-4cbb-89e7-7ba47d251cbd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 1</th>\n","      <th>Unnamed: 0.1</th>\n","      <th>DHSID_EA</th>\n","      <th>year</th>\n","      <th>cc</th>\n","      <th>lat</th>\n","      <th>lon</th>\n","      <th>women_edu</th>\n","      <th>path</th>\n","      <th>img_captured_at</th>\n","      <th>img_lon</th>\n","      <th>img_lat</th>\n","      <th>img_id</th>\n","      <th>img_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>74101</td>\n","      <td>74101</td>\n","      <td>AM-2010-6#-00000175</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.865949</td>\n","      <td>44.052637</td>\n","      <td>10.307692</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1341142789364</td>\n","      <td>44.118895</td>\n","      <td>40.914849</td>\n","      <td>455621522386245</td>\n","      <td>AM/AM-2010-6#-00000175/455621522386245.jpeg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>74102</td>\n","      <td>74102</td>\n","      <td>AM-2010-6#-00000176</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.878055</td>\n","      <td>44.042707</td>\n","      <td>10.761905</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1341142789364</td>\n","      <td>44.118895</td>\n","      <td>40.914849</td>\n","      <td>455621522386245</td>\n","      <td>AM/AM-2010-6#-00000176/455621522386245.jpeg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>74103</td>\n","      <td>74103</td>\n","      <td>AM-2010-6#-00000215</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.776914</td>\n","      <td>43.841243</td>\n","      <td>12.476190</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1295470496500</td>\n","      <td>43.853536</td>\n","      <td>40.802320</td>\n","      <td>448238129596253</td>\n","      <td>AM/AM-2010-6#-00000215/448238129596253.jpeg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>74104</td>\n","      <td>74104</td>\n","      <td>AM-2010-6#-00000218</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.808131</td>\n","      <td>43.840526</td>\n","      <td>12.600000</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1295470496500</td>\n","      <td>43.852432</td>\n","      <td>40.798289</td>\n","      <td>803317710311828</td>\n","      <td>AM/AM-2010-6#-00000218/803317710311828.jpeg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>74105</td>\n","      <td>74105</td>\n","      <td>AM-2010-6#-00000232</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.765091</td>\n","      <td>43.783366</td>\n","      <td>11.480000</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1295470496500</td>\n","      <td>43.853536</td>\n","      <td>40.802320</td>\n","      <td>448238129596253</td>\n","      <td>AM/AM-2010-6#-00000232/448238129596253.jpeg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aee304d-d80c-4cbb-89e7-7ba47d251cbd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5aee304d-d80c-4cbb-89e7-7ba47d251cbd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5aee304d-d80c-4cbb-89e7-7ba47d251cbd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df['img_path'] = dataset_root_dir + df['img_path']\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"-_IfIqTp-BW1","executionInfo":{"status":"ok","timestamp":1669915956064,"user_tz":480,"elapsed":1112,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"cec6406a-84b0-4019-85ad-f2fb9e00e874"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  Unnamed: 1  Unnamed: 0.1             DHSID_EA  year  cc  \\\n","0           0       74101         74101  AM-2010-6#-00000175  2010  AM   \n","1           1       74102         74102  AM-2010-6#-00000176  2010  AM   \n","2           2       74103         74103  AM-2010-6#-00000215  2010  AM   \n","3           3       74104         74104  AM-2010-6#-00000218  2010  AM   \n","4           4       74105         74105  AM-2010-6#-00000232  2010  AM   \n","\n","         lat        lon  women_edu  \\\n","0  40.865949  44.052637  10.307692   \n","1  40.878055  44.042707  10.761905   \n","2  40.776914  43.841243  12.476190   \n","3  40.808131  43.840526  12.600000   \n","4  40.765091  43.783366  11.480000   \n","\n","                                                path  img_captured_at  \\\n","0  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1341142789364   \n","1  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1341142789364   \n","2  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1295470496500   \n","3  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1295470496500   \n","4  /content/drive/MyDrive/Colab Notebooks/cs230/w...    1295470496500   \n","\n","     img_lon    img_lat           img_id  \\\n","0  44.118895  40.914849  455621522386245   \n","1  44.118895  40.914849  455621522386245   \n","2  43.853536  40.802320  448238129596253   \n","3  43.852432  40.798289  803317710311828   \n","4  43.853536  40.802320  448238129596253   \n","\n","                                            img_path  \n","0  /content/drive/MyDrive/Colab Notebooks/cs230/w...  \n","1  /content/drive/MyDrive/Colab Notebooks/cs230/w...  \n","2  /content/drive/MyDrive/Colab Notebooks/cs230/w...  \n","3  /content/drive/MyDrive/Colab Notebooks/cs230/w...  \n","4  /content/drive/MyDrive/Colab Notebooks/cs230/w...  "],"text/html":["\n","  <div id=\"df-b4b14596-988d-4068-b9af-348098a66765\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 1</th>\n","      <th>Unnamed: 0.1</th>\n","      <th>DHSID_EA</th>\n","      <th>year</th>\n","      <th>cc</th>\n","      <th>lat</th>\n","      <th>lon</th>\n","      <th>women_edu</th>\n","      <th>path</th>\n","      <th>img_captured_at</th>\n","      <th>img_lon</th>\n","      <th>img_lat</th>\n","      <th>img_id</th>\n","      <th>img_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>74101</td>\n","      <td>74101</td>\n","      <td>AM-2010-6#-00000175</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.865949</td>\n","      <td>44.052637</td>\n","      <td>10.307692</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1341142789364</td>\n","      <td>44.118895</td>\n","      <td>40.914849</td>\n","      <td>455621522386245</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>74102</td>\n","      <td>74102</td>\n","      <td>AM-2010-6#-00000176</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.878055</td>\n","      <td>44.042707</td>\n","      <td>10.761905</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1341142789364</td>\n","      <td>44.118895</td>\n","      <td>40.914849</td>\n","      <td>455621522386245</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>74103</td>\n","      <td>74103</td>\n","      <td>AM-2010-6#-00000215</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.776914</td>\n","      <td>43.841243</td>\n","      <td>12.476190</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1295470496500</td>\n","      <td>43.853536</td>\n","      <td>40.802320</td>\n","      <td>448238129596253</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>74104</td>\n","      <td>74104</td>\n","      <td>AM-2010-6#-00000218</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.808131</td>\n","      <td>43.840526</td>\n","      <td>12.600000</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1295470496500</td>\n","      <td>43.852432</td>\n","      <td>40.798289</td>\n","      <td>803317710311828</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>74105</td>\n","      <td>74105</td>\n","      <td>AM-2010-6#-00000232</td>\n","      <td>2010</td>\n","      <td>AM</td>\n","      <td>40.765091</td>\n","      <td>43.783366</td>\n","      <td>11.480000</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>1295470496500</td>\n","      <td>43.853536</td>\n","      <td>40.802320</td>\n","      <td>448238129596253</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4b14596-988d-4068-b9af-348098a66765')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b4b14596-988d-4068-b9af-348098a66765 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b4b14596-988d-4068-b9af-348098a66765');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# for now exclude these folders \n","# df = df[ df['cc'] != 'BJ'] # need to resize\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IBPB66uGbW0","executionInfo":{"status":"ok","timestamp":1669883161670,"user_tz":480,"elapsed":203,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"4e874b40-473e-45d2-9254-2b0cd758d475"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7614"]},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["# collapse the dataset s.t. each row is a satellite path with a list of img paths \n","dhsid_df = df.groupby(['DHSID_EA', 'year', 'women_edu', 'path'])['img_path'].apply(list).reset_index()\n","dhsid_df.tail(10) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"LYuvsLULl6o5","executionInfo":{"status":"ok","timestamp":1669916560716,"user_tz":480,"elapsed":500,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"bd5af146-5be0-4353-8430-f99deac65e64"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 DHSID_EA  year  women_edu  \\\n","1883  ZW-2015-7#-00000362  2015  12.030303   \n","1884  ZW-2015-7#-00000369  2015  10.391304   \n","1885  ZW-2015-7#-00000374  2015  10.406250   \n","1886  ZW-2015-7#-00000378  2015  10.741935   \n","1887  ZW-2015-7#-00000381  2015  11.303030   \n","1888  ZW-2015-7#-00000390  2015  11.521739   \n","1889  ZW-2015-7#-00000392  2015   9.800000   \n","1890  ZW-2015-7#-00000394  2015   9.594595   \n","1891  ZW-2015-7#-00000396  2015   9.750000   \n","1892  ZW-2015-7#-00000399  2015  11.243243   \n","\n","                                                   path  \\\n","1883  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1884  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1885  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1886  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1887  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1888  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1889  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1890  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1891  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","1892  /content/drive/MyDrive/Colab Notebooks/cs230/w...   \n","\n","                                               img_path  \n","1883  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1884  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1885  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1886  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1887  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1888  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1889  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1890  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1891  [/content/drive/MyDrive/Colab Notebooks/cs230/...  \n","1892  [/content/drive/MyDrive/Colab Notebooks/cs230/...  "],"text/html":["\n","  <div id=\"df-da14c7bb-c4a3-4b15-85eb-10bd56e59690\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DHSID_EA</th>\n","      <th>year</th>\n","      <th>women_edu</th>\n","      <th>path</th>\n","      <th>img_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1883</th>\n","      <td>ZW-2015-7#-00000362</td>\n","      <td>2015</td>\n","      <td>12.030303</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1884</th>\n","      <td>ZW-2015-7#-00000369</td>\n","      <td>2015</td>\n","      <td>10.391304</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1885</th>\n","      <td>ZW-2015-7#-00000374</td>\n","      <td>2015</td>\n","      <td>10.406250</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1886</th>\n","      <td>ZW-2015-7#-00000378</td>\n","      <td>2015</td>\n","      <td>10.741935</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1887</th>\n","      <td>ZW-2015-7#-00000381</td>\n","      <td>2015</td>\n","      <td>11.303030</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1888</th>\n","      <td>ZW-2015-7#-00000390</td>\n","      <td>2015</td>\n","      <td>11.521739</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1889</th>\n","      <td>ZW-2015-7#-00000392</td>\n","      <td>2015</td>\n","      <td>9.800000</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1890</th>\n","      <td>ZW-2015-7#-00000394</td>\n","      <td>2015</td>\n","      <td>9.594595</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1891</th>\n","      <td>ZW-2015-7#-00000396</td>\n","      <td>2015</td>\n","      <td>9.750000</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","    <tr>\n","      <th>1892</th>\n","      <td>ZW-2015-7#-00000399</td>\n","      <td>2015</td>\n","      <td>11.243243</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/cs230/w...</td>\n","      <td>[/content/drive/MyDrive/Colab Notebooks/cs230/...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da14c7bb-c4a3-4b15-85eb-10bd56e59690')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-da14c7bb-c4a3-4b15-85eb-10bd56e59690 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-da14c7bb-c4a3-4b15-85eb-10bd56e59690');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["dhsid_df['img_path'][100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbUwWZI-xZI_","executionInfo":{"status":"ok","timestamp":1669916571919,"user_tz":480,"elapsed":20,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"e3e729c8-908b-4d57-8372-a2fde631aa22"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu/data/AM/AM-2016-7#-00000097/1161818567600875.jpeg',\n"," '/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu/data/AM/AM-2016-7#-00000097/3911978088838780.jpeg',\n"," '/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu/data/AM/AM-2016-7#-00000097/325791582223174.jpeg',\n"," '/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu/data/AM/AM-2016-7#-00000097/340195134193338.jpeg',\n"," '/content/drive/MyDrive/Colab Notebooks/cs230/womens_edu/data/AM/AM-2016-7#-00000097/316863043145729.jpeg']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# dhsid_df.to_csv('data/multi_modal_input.csv')"],"metadata":{"id":"DHE4wCTAeI13"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"F_mr_Fj6dXZK"}},{"cell_type":"code","source":["def get_street_tensor(img_path_list):\n","  image_tensor_list = [] \n","  for img_path in img_path_list:\n","    image = io.imread(img_path)\n","    image = (image - image.min()) / (image.max() - image.min())\n","    image_tensor = torch.from_numpy(image)     \n","    image_tensor = image_tensor.permute(2,0,1).float()\n","    #print(image_tensor.shape)\n","    #print(img_path)\n","    image_tensor_list.append(image_tensor)\n","\n","  return image_tensor_list"],"metadata":{"id":"UhnuHCRF3on7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_satellite_tensor(img_path):\n","    image = io.imread(img_path)\n","    image = image[:3]\n","    image = image[::-1]\n","    image = (image - image.min()) / (image.max() - image.min())\n","    image_tensor = torch.from_numpy(image)     \n","\n","    return image_tensor "],"metadata":{"id":"xhfJGHrS33Kt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combined Dataset class \n","class DHSIDDataset(Dataset):\n","  def __init__(self, df):\n","    self.satellite_path = df['path'].to_numpy()\n","    self.street_path = df['img_path'].to_numpy() # a list of paths \n","    self.targets = df['women_edu'].to_numpy()\n","\n","  def __len__(self):\n","    return self.satellite_path.shape[0] \n","\n","  def __getitem__(self, idx):\n","    sat_tensor = get_satellite_tensor(self.satellite_path[idx])\n","    street_tensor_list = get_street_tensor(self.street_path[idx]) # a list of tensors \n","    target = torch.Tensor(np.array([self.targets[idx]]))\n","\n","    return sat_tensor, street_tensor_list, target"],"metadata":{"id":"JuCF77524YuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"zDrgLqlQbUUR"}},{"cell_type":"code","source":["def create_model(model):\n","    if model == 'resnet18':\n","        model = models.resnet18(pretrained=True)\n","    elif model == 'resnet34':\n","        model = models.resnet34(pretrained=True)\n","    elif model == 'resnet50':\n","        model = models.resnet50(pretrained=True)\n","    model = nn.Sequential(*list(model.children())[:-1]) # get model only up to second to last layer \n","    return model"],"metadata":{"id":"VE1UfKCMkkZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SatelliteStreetModel(nn.Module):\n","  def __init__(self, sat_model, street_model):\n","    super(SatelliteStreetModel, self).__init__()\n","\n","    self.satellite_model = create_model(sat_model)\n","    self.street_model = create_model(street_model)\n","\n","    self.fc = nn.Linear(512*2, 1)\n","\n","  def forward(self, sat_x, street_x):\n","    satellite_fv = self.satellite_model(sat_x)\n","    satellite_fv = torch.flatten(satellite_fv , start_dim=2)\n","    # print(satellite_fv.shape)\n","    street_fv = self.street_model(street_x) \n","    street_fv = torch.mean(street_fv, 0)\n","    street_fv = torch.flatten(satellite_fv, start_dim=2)\n","    # print(satellite_fv.shape, street_fv.shape)\n","    # print(street_fv.shape)\n","    concat_fv = torch.cat( (satellite_fv, street_fv), dim=1)\n","    # print(concat_fv.shape)\n","    # TO DO: add more Dense/FC layers\n","    concat_fv = torch.squeeze(concat_fv)\n","    # print(concat_fv.shape)\n","    out = self.fc(concat_fv)\n","    # print(out.shape)\n","    return out"],"metadata":{"id":"iAumopwn3cd4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"XQQjRAjacXTJ"}},{"cell_type":"code","source":["# use GPU \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sPO5QBvrwBk","executionInfo":{"status":"ok","timestamp":1669916590650,"user_tz":480,"elapsed":723,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"d15b69ec-a8ba-4280-bb1b-c9d6b32a5757"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def train_model(model, train_loader, criterion, optimizer, num_epochs, device, batch_size, verbose=True):\n","    batch_size = torch.from_numpy(np.array(batch_size)).to(device)\n","    \n","    for epoch in range(1, num_epochs + 1):\n","        batch_num = 1\n","\n","        loss = 0.0\n","        optimizer.zero_grad()\n","        for sat_inputs, street_inputs, targets in train_loader:\n","            sat_inputs = sat_inputs.to(device)\n","            targets = targets.to(device)\n","\n","            street_inputs = torch.stack(street_inputs, dim=1).squeeze(0)\n","            street_inputs = street_inputs.to(device)\n","\n","            output = model(sat_inputs, street_inputs)\n","            # print(output, targets[0])\n","            loss += criterion(output, targets[0]) / batch_size\n","\n","            if batch_num % batch_size.item() == 0:\n","              loss.backward()\n","              optimizer.step()\n","              optimizer.zero_grad()\n","\n","              if verbose:                              \n","                print(f'Epoch [{epoch}/{num_epochs}], Step [{batch_num}/{len(train_loader)}], '\n","                      f'Loss: {loss.item():.4f}')\n","              \n","              loss = 0.0\n","            \n","            batch_num += 1"],"metadata":{"id":"CiUBPXZaAPWv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 128\n","LEARNING_RATE = 0.003\n","NUM_EPOCHS = 50 # tune this "],"metadata":{"id":"jnqtf_pkfq4t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TO TEST\n","dhsid_df = dhsid_df.sample(frac=1)\n","# dhsid_df = dhsid_df[:500,]\n","\n","imgs = DHSIDDataset(dhsid_df)\n","loader = DataLoader(imgs, batch_size=1, num_workers=2)\n","\n","model = SatelliteStreetModel('resnet18', 'resnet18') # resnet18 is the best model for satellite model\n","model = model.to(device)\n","criterion = torch.nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-3)"],"metadata":{"id":"HZxVdv5PCqiG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(model, loader, criterion, optimizer, NUM_EPOCHS, device, BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWzJ4zvzL0z_","outputId":"48223bc3-0974-479f-bdba-b677c7d61a32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Step [128/1893], Loss: 63.5259\n","Epoch [1/50], Step [256/1893], Loss: 56.7263\n","Epoch [1/50], Step [384/1893], Loss: 39.7190\n","Epoch [1/50], Step [512/1893], Loss: 31.1758\n","Epoch [1/50], Step [640/1893], Loss: 16.5413\n","Epoch [1/50], Step [768/1893], Loss: 10.7755\n","Epoch [1/50], Step [896/1893], Loss: 10.6921\n","Epoch [1/50], Step [1024/1893], Loss: 11.0203\n","Epoch [1/50], Step [1152/1893], Loss: 11.4650\n","Epoch [1/50], Step [1280/1893], Loss: 13.8155\n","Epoch [1/50], Step [1408/1893], Loss: 12.7738\n","Epoch [1/50], Step [1536/1893], Loss: 9.0178\n","Epoch [1/50], Step [1664/1893], Loss: 11.2462\n","Epoch [1/50], Step [1792/1893], Loss: 12.1072\n","Epoch [2/50], Step [128/1893], Loss: 11.0309\n","Epoch [2/50], Step [256/1893], Loss: 10.4906\n","Epoch [2/50], Step [384/1893], Loss: 9.9480\n","Epoch [2/50], Step [512/1893], Loss: 11.7824\n","Epoch [2/50], Step [640/1893], Loss: 9.4712\n","Epoch [2/50], Step [768/1893], Loss: 9.8867\n","Epoch [2/50], Step [896/1893], Loss: 10.4938\n","Epoch [2/50], Step [1024/1893], Loss: 11.1192\n","Epoch [2/50], Step [1152/1893], Loss: 10.4285\n","Epoch [2/50], Step [1280/1893], Loss: 11.4754\n","Epoch [2/50], Step [1408/1893], Loss: 11.6215\n","Epoch [2/50], Step [1536/1893], Loss: 8.4724\n","Epoch [2/50], Step [1664/1893], Loss: 10.5171\n","Epoch [2/50], Step [1792/1893], Loss: 11.5625\n","Epoch [3/50], Step [128/1893], Loss: 11.0177\n","Epoch [3/50], Step [256/1893], Loss: 10.4468\n","Epoch [3/50], Step [384/1893], Loss: 9.8840\n","Epoch [3/50], Step [512/1893], Loss: 11.8103\n","Epoch [3/50], Step [640/1893], Loss: 9.5861\n","Epoch [3/50], Step [768/1893], Loss: 9.7611\n","Epoch [3/50], Step [896/1893], Loss: 10.8271\n","Epoch [3/50], Step [1024/1893], Loss: 11.4721\n","Epoch [3/50], Step [1152/1893], Loss: 10.4746\n","Epoch [3/50], Step [1280/1893], Loss: 11.2029\n","Epoch [3/50], Step [1408/1893], Loss: 11.4718\n","Epoch [3/50], Step [1536/1893], Loss: 8.3296\n","Epoch [3/50], Step [1664/1893], Loss: 10.3936\n","Epoch [3/50], Step [1792/1893], Loss: 11.7942\n","Epoch [4/50], Step [128/1893], Loss: 11.1365\n","Epoch [4/50], Step [256/1893], Loss: 10.4264\n","Epoch [4/50], Step [384/1893], Loss: 9.4285\n","Epoch [4/50], Step [512/1893], Loss: 11.3740\n","Epoch [4/50], Step [640/1893], Loss: 9.1753\n","Epoch [4/50], Step [768/1893], Loss: 9.4475\n","Epoch [4/50], Step [896/1893], Loss: 10.1087\n","Epoch [4/50], Step [1024/1893], Loss: 10.6640\n","Epoch [4/50], Step [1152/1893], Loss: 10.0007\n","Epoch [4/50], Step [1280/1893], Loss: 10.9307\n","Epoch [4/50], Step [1408/1893], Loss: 11.1775\n","Epoch [4/50], Step [1536/1893], Loss: 7.9403\n","Epoch [4/50], Step [1664/1893], Loss: 9.6006\n","Epoch [4/50], Step [1792/1893], Loss: 10.2553\n","Epoch [5/50], Step [128/1893], Loss: 10.6058\n","Epoch [5/50], Step [256/1893], Loss: 10.2472\n","Epoch [5/50], Step [384/1893], Loss: 8.6563\n","Epoch [5/50], Step [512/1893], Loss: 10.7568\n","Epoch [5/50], Step [640/1893], Loss: 9.2112\n","Epoch [5/50], Step [768/1893], Loss: 10.0359\n","Epoch [5/50], Step [896/1893], Loss: 9.9585\n","Epoch [5/50], Step [1024/1893], Loss: 10.3962\n","Epoch [5/50], Step [1152/1893], Loss: 9.8800\n","Epoch [5/50], Step [1280/1893], Loss: 10.7928\n","Epoch [5/50], Step [1408/1893], Loss: 10.8991\n","Epoch [5/50], Step [1536/1893], Loss: 8.3107\n","Epoch [5/50], Step [1664/1893], Loss: 9.8677\n","Epoch [5/50], Step [1792/1893], Loss: 10.0880\n","Epoch [6/50], Step [128/1893], Loss: 9.8289\n","Epoch [6/50], Step [256/1893], Loss: 9.7402\n","Epoch [6/50], Step [384/1893], Loss: 8.5455\n","Epoch [6/50], Step [512/1893], Loss: 9.8472\n","Epoch [6/50], Step [640/1893], Loss: 8.1055\n","Epoch [6/50], Step [768/1893], Loss: 7.8480\n","Epoch [6/50], Step [896/1893], Loss: 9.1026\n","Epoch [6/50], Step [1024/1893], Loss: 9.2177\n","Epoch [6/50], Step [1152/1893], Loss: 9.0976\n","Epoch [6/50], Step [1280/1893], Loss: 9.3319\n","Epoch [6/50], Step [1408/1893], Loss: 9.9645\n","Epoch [6/50], Step [1536/1893], Loss: 7.3328\n","Epoch [6/50], Step [1664/1893], Loss: 8.4518\n","Epoch [6/50], Step [1792/1893], Loss: 7.8470\n","Epoch [7/50], Step [128/1893], Loss: 9.1617\n","Epoch [7/50], Step [256/1893], Loss: 9.8376\n","Epoch [7/50], Step [384/1893], Loss: 7.4251\n","Epoch [7/50], Step [512/1893], Loss: 7.7354\n","Epoch [7/50], Step [640/1893], Loss: 7.7864\n","Epoch [7/50], Step [768/1893], Loss: 6.5929\n","Epoch [7/50], Step [896/1893], Loss: 8.7521\n","Epoch [7/50], Step [1024/1893], Loss: 11.5658\n","Epoch [7/50], Step [1152/1893], Loss: 8.0785\n","Epoch [7/50], Step [1280/1893], Loss: 7.9979\n","Epoch [7/50], Step [1408/1893], Loss: 8.1405\n","Epoch [7/50], Step [1536/1893], Loss: 6.1400\n","Epoch [7/50], Step [1664/1893], Loss: 8.0956\n","Epoch [7/50], Step [1792/1893], Loss: 7.3775\n","Epoch [8/50], Step [128/1893], Loss: 8.2112\n","Epoch [8/50], Step [256/1893], Loss: 9.8630\n","Epoch [8/50], Step [384/1893], Loss: 9.5595\n","Epoch [8/50], Step [512/1893], Loss: 8.7736\n","Epoch [8/50], Step [640/1893], Loss: 7.1230\n","Epoch [8/50], Step [768/1893], Loss: 8.3130\n","Epoch [8/50], Step [896/1893], Loss: 9.1845\n","Epoch [8/50], Step [1024/1893], Loss: 8.6462\n","Epoch [8/50], Step [1152/1893], Loss: 7.7008\n","Epoch [8/50], Step [1280/1893], Loss: 7.9743\n","Epoch [8/50], Step [1408/1893], Loss: 8.3546\n","Epoch [8/50], Step [1536/1893], Loss: 7.4956\n","Epoch [8/50], Step [1664/1893], Loss: 8.5604\n","Epoch [8/50], Step [1792/1893], Loss: 7.1863\n","Epoch [9/50], Step [128/1893], Loss: 7.8726\n","Epoch [9/50], Step [256/1893], Loss: 8.6019\n","Epoch [9/50], Step [384/1893], Loss: 8.2612\n","Epoch [9/50], Step [512/1893], Loss: 7.4803\n","Epoch [9/50], Step [640/1893], Loss: 7.0202\n","Epoch [9/50], Step [768/1893], Loss: 7.4438\n","Epoch [9/50], Step [896/1893], Loss: 7.9700\n","Epoch [9/50], Step [1024/1893], Loss: 7.9853\n","Epoch [9/50], Step [1152/1893], Loss: 7.1242\n","Epoch [9/50], Step [1280/1893], Loss: 7.1680\n","Epoch [9/50], Step [1408/1893], Loss: 7.5526\n","Epoch [9/50], Step [1536/1893], Loss: 6.6659\n","Epoch [9/50], Step [1664/1893], Loss: 6.4641\n","Epoch [9/50], Step [1792/1893], Loss: 6.1781\n","Epoch [10/50], Step [128/1893], Loss: 7.9403\n","Epoch [10/50], Step [256/1893], Loss: 6.9820\n","Epoch [10/50], Step [384/1893], Loss: 7.3193\n","Epoch [10/50], Step [512/1893], Loss: 6.5830\n","Epoch [10/50], Step [640/1893], Loss: 6.2243\n","Epoch [10/50], Step [768/1893], Loss: 6.2488\n","Epoch [10/50], Step [896/1893], Loss: 7.3483\n","Epoch [10/50], Step [1024/1893], Loss: 7.3985\n","Epoch [10/50], Step [1152/1893], Loss: 6.5005\n","Epoch [10/50], Step [1280/1893], Loss: 7.0553\n","Epoch [10/50], Step [1408/1893], Loss: 7.8507\n","Epoch [10/50], Step [1536/1893], Loss: 4.7709\n","Epoch [10/50], Step [1664/1893], Loss: 6.9147\n","Epoch [10/50], Step [1792/1893], Loss: 7.4743\n","Epoch [11/50], Step [128/1893], Loss: 6.5719\n","Epoch [11/50], Step [256/1893], Loss: 7.0975\n","Epoch [11/50], Step [384/1893], Loss: 7.7903\n","Epoch [11/50], Step [512/1893], Loss: 6.1905\n","Epoch [11/50], Step [640/1893], Loss: 6.0783\n","Epoch [11/50], Step [768/1893], Loss: 5.8304\n","Epoch [11/50], Step [896/1893], Loss: 6.9212\n","Epoch [11/50], Step [1024/1893], Loss: 6.4756\n","Epoch [11/50], Step [1152/1893], Loss: 6.3062\n","Epoch [11/50], Step [1280/1893], Loss: 6.2534\n","Epoch [11/50], Step [1408/1893], Loss: 6.4583\n","Epoch [11/50], Step [1536/1893], Loss: 5.0457\n","Epoch [11/50], Step [1664/1893], Loss: 5.8253\n","Epoch [11/50], Step [1792/1893], Loss: 5.6512\n","Epoch [12/50], Step [128/1893], Loss: 6.5962\n","Epoch [12/50], Step [256/1893], Loss: 5.6553\n","Epoch [12/50], Step [384/1893], Loss: 6.3238\n","Epoch [12/50], Step [512/1893], Loss: 5.3495\n","Epoch [12/50], Step [640/1893], Loss: 5.8451\n","Epoch [12/50], Step [768/1893], Loss: 5.5548\n","Epoch [12/50], Step [896/1893], Loss: 5.7910\n","Epoch [12/50], Step [1024/1893], Loss: 6.1468\n","Epoch [12/50], Step [1152/1893], Loss: 4.8918\n","Epoch [12/50], Step [1280/1893], Loss: 5.3811\n","Epoch [12/50], Step [1408/1893], Loss: 6.6138\n","Epoch [12/50], Step [1536/1893], Loss: 4.5557\n","Epoch [12/50], Step [1664/1893], Loss: 5.6639\n","Epoch [12/50], Step [1792/1893], Loss: 5.3400\n","Epoch [13/50], Step [128/1893], Loss: 6.1873\n","Epoch [13/50], Step [256/1893], Loss: 5.7415\n","Epoch [13/50], Step [384/1893], Loss: 5.8414\n","Epoch [13/50], Step [512/1893], Loss: 4.9165\n","Epoch [13/50], Step [640/1893], Loss: 5.1515\n","Epoch [13/50], Step [768/1893], Loss: 5.1548\n","Epoch [13/50], Step [896/1893], Loss: 5.2617\n","Epoch [13/50], Step [1024/1893], Loss: 5.7051\n","Epoch [13/50], Step [1152/1893], Loss: 4.6216\n","Epoch [13/50], Step [1280/1893], Loss: 5.5620\n","Epoch [13/50], Step [1408/1893], Loss: 6.0425\n","Epoch [13/50], Step [1536/1893], Loss: 4.6249\n","Epoch [13/50], Step [1664/1893], Loss: 5.7176\n","Epoch [13/50], Step [1792/1893], Loss: 4.9045\n","Epoch [14/50], Step [128/1893], Loss: 5.9075\n","Epoch [14/50], Step [256/1893], Loss: 6.9163\n","Epoch [14/50], Step [384/1893], Loss: 4.7516\n","Epoch [14/50], Step [512/1893], Loss: 4.7832\n","Epoch [14/50], Step [640/1893], Loss: 5.4621\n","Epoch [14/50], Step [768/1893], Loss: 4.6995\n","Epoch [14/50], Step [896/1893], Loss: 4.9431\n","Epoch [14/50], Step [1024/1893], Loss: 5.6663\n","Epoch [14/50], Step [1152/1893], Loss: 4.1102\n","Epoch [14/50], Step [1280/1893], Loss: 5.2981\n","Epoch [14/50], Step [1408/1893], Loss: 5.9243\n","Epoch [14/50], Step [1536/1893], Loss: 4.1217\n","Epoch [14/50], Step [1664/1893], Loss: 5.6373\n","Epoch [14/50], Step [1792/1893], Loss: 6.8673\n","Epoch [15/50], Step [128/1893], Loss: 5.9665\n","Epoch [15/50], Step [256/1893], Loss: 4.9841\n","Epoch [15/50], Step [384/1893], Loss: 5.3408\n","Epoch [15/50], Step [512/1893], Loss: 5.5929\n","Epoch [15/50], Step [640/1893], Loss: 4.8079\n","Epoch [15/50], Step [768/1893], Loss: 4.5946\n","Epoch [15/50], Step [896/1893], Loss: 6.1311\n","Epoch [15/50], Step [1024/1893], Loss: 5.6725\n","Epoch [15/50], Step [1152/1893], Loss: 4.2215\n","Epoch [15/50], Step [1280/1893], Loss: 4.7807\n","Epoch [15/50], Step [1408/1893], Loss: 6.0227\n","Epoch [15/50], Step [1536/1893], Loss: 4.0279\n","Epoch [15/50], Step [1664/1893], Loss: 4.7736\n","Epoch [15/50], Step [1792/1893], Loss: 5.7838\n","Epoch [16/50], Step [128/1893], Loss: 5.7945\n","Epoch [16/50], Step [256/1893], Loss: 4.5863\n","Epoch [16/50], Step [384/1893], Loss: 5.3878\n","Epoch [16/50], Step [512/1893], Loss: 4.3495\n","Epoch [16/50], Step [640/1893], Loss: 4.4404\n","Epoch [16/50], Step [768/1893], Loss: 4.3975\n","Epoch [16/50], Step [896/1893], Loss: 5.3373\n","Epoch [16/50], Step [1024/1893], Loss: 5.4379\n","Epoch [16/50], Step [1152/1893], Loss: 3.7585\n","Epoch [16/50], Step [1280/1893], Loss: 4.7489\n","Epoch [16/50], Step [1408/1893], Loss: 5.2953\n","Epoch [16/50], Step [1536/1893], Loss: 3.6982\n","Epoch [16/50], Step [1664/1893], Loss: 4.6527\n","Epoch [16/50], Step [1792/1893], Loss: 5.9056\n","Epoch [17/50], Step [128/1893], Loss: 5.0975\n","Epoch [17/50], Step [256/1893], Loss: 3.6938\n","Epoch [17/50], Step [384/1893], Loss: 4.7765\n","Epoch [17/50], Step [512/1893], Loss: 5.0913\n","Epoch [17/50], Step [640/1893], Loss: 4.5654\n","Epoch [17/50], Step [768/1893], Loss: 3.9766\n","Epoch [17/50], Step [896/1893], Loss: 5.0721\n","Epoch [17/50], Step [1024/1893], Loss: 5.9844\n","Epoch [17/50], Step [1152/1893], Loss: 3.6219\n","Epoch [17/50], Step [1280/1893], Loss: 4.1480\n","Epoch [17/50], Step [1408/1893], Loss: 5.0794\n","Epoch [17/50], Step [1536/1893], Loss: 3.6512\n","Epoch [17/50], Step [1664/1893], Loss: 4.0725\n","Epoch [17/50], Step [1792/1893], Loss: 4.9640\n","Epoch [18/50], Step [128/1893], Loss: 5.0313\n","Epoch [18/50], Step [256/1893], Loss: 3.6988\n","Epoch [18/50], Step [384/1893], Loss: 4.0774\n","Epoch [18/50], Step [512/1893], Loss: 4.5434\n","Epoch [18/50], Step [640/1893], Loss: 4.4635\n","Epoch [18/50], Step [768/1893], Loss: 3.7380\n","Epoch [18/50], Step [896/1893], Loss: 4.6160\n","Epoch [18/50], Step [1024/1893], Loss: 4.7569\n","Epoch [18/50], Step [1152/1893], Loss: 3.5228\n","Epoch [18/50], Step [1280/1893], Loss: 3.7712\n","Epoch [18/50], Step [1408/1893], Loss: 4.9524\n","Epoch [18/50], Step [1536/1893], Loss: 3.7860\n","Epoch [18/50], Step [1664/1893], Loss: 4.4236\n","Epoch [18/50], Step [1792/1893], Loss: 4.3738\n","Epoch [19/50], Step [128/1893], Loss: 4.4550\n","Epoch [19/50], Step [256/1893], Loss: 3.0997\n","Epoch [19/50], Step [384/1893], Loss: 3.2223\n","Epoch [19/50], Step [512/1893], Loss: 3.6443\n","Epoch [19/50], Step [640/1893], Loss: 3.9550\n","Epoch [19/50], Step [768/1893], Loss: 3.5641\n","Epoch [19/50], Step [896/1893], Loss: 3.8474\n","Epoch [19/50], Step [1024/1893], Loss: 4.5373\n","Epoch [19/50], Step [1152/1893], Loss: 4.2548\n","Epoch [19/50], Step [1280/1893], Loss: 4.0163\n","Epoch [19/50], Step [1408/1893], Loss: 4.0084\n","Epoch [19/50], Step [1536/1893], Loss: 4.3450\n","Epoch [19/50], Step [1664/1893], Loss: 3.8158\n","Epoch [19/50], Step [1792/1893], Loss: 3.6586\n","Epoch [20/50], Step [128/1893], Loss: 4.8354\n","Epoch [20/50], Step [256/1893], Loss: 3.4907\n","Epoch [20/50], Step [384/1893], Loss: 3.6678\n","Epoch [20/50], Step [512/1893], Loss: 4.4847\n","Epoch [20/50], Step [640/1893], Loss: 4.5455\n","Epoch [20/50], Step [768/1893], Loss: 3.0149\n","Epoch [20/50], Step [896/1893], Loss: 3.5951\n","Epoch [20/50], Step [1024/1893], Loss: 4.3353\n","Epoch [20/50], Step [1152/1893], Loss: 3.2237\n","Epoch [20/50], Step [1280/1893], Loss: 3.2291\n","Epoch [20/50], Step [1408/1893], Loss: 3.7488\n","Epoch [20/50], Step [1536/1893], Loss: 3.1298\n","Epoch [20/50], Step [1664/1893], Loss: 3.8724\n","Epoch [20/50], Step [1792/1893], Loss: 3.5781\n","Epoch [21/50], Step [128/1893], Loss: 3.8419\n","Epoch [21/50], Step [256/1893], Loss: 3.4938\n","Epoch [21/50], Step [384/1893], Loss: 3.8972\n","Epoch [21/50], Step [512/1893], Loss: 3.3135\n","Epoch [21/50], Step [640/1893], Loss: 3.7490\n","Epoch [21/50], Step [768/1893], Loss: 3.5103\n","Epoch [21/50], Step [896/1893], Loss: 3.4996\n","Epoch [21/50], Step [1024/1893], Loss: 4.0017\n","Epoch [21/50], Step [1152/1893], Loss: 3.3236\n","Epoch [21/50], Step [1280/1893], Loss: 3.8223\n","Epoch [21/50], Step [1408/1893], Loss: 3.8723\n","Epoch [21/50], Step [1536/1893], Loss: 2.5146\n","Epoch [21/50], Step [1664/1893], Loss: 4.2550\n","Epoch [21/50], Step [1792/1893], Loss: 3.9027\n","Epoch [22/50], Step [128/1893], Loss: 3.3668\n","Epoch [22/50], Step [256/1893], Loss: 2.6793\n","Epoch [22/50], Step [384/1893], Loss: 3.3622\n","Epoch [22/50], Step [512/1893], Loss: 3.2727\n","Epoch [22/50], Step [640/1893], Loss: 2.8388\n","Epoch [22/50], Step [768/1893], Loss: 2.9505\n","Epoch [22/50], Step [896/1893], Loss: 3.3643\n","Epoch [22/50], Step [1024/1893], Loss: 3.3565\n","Epoch [22/50], Step [1152/1893], Loss: 2.6560\n","Epoch [22/50], Step [1280/1893], Loss: 3.4677\n","Epoch [22/50], Step [1408/1893], Loss: 3.6934\n","Epoch [22/50], Step [1536/1893], Loss: 2.4564\n","Epoch [22/50], Step [1664/1893], Loss: 3.7950\n","Epoch [22/50], Step [1792/1893], Loss: 3.2098\n","Epoch [23/50], Step [128/1893], Loss: 3.6036\n","Epoch [23/50], Step [256/1893], Loss: 3.0117\n","Epoch [23/50], Step [384/1893], Loss: 3.2278\n","Epoch [23/50], Step [512/1893], Loss: 2.8524\n","Epoch [23/50], Step [640/1893], Loss: 2.6153\n","Epoch [23/50], Step [768/1893], Loss: 2.4420\n","Epoch [23/50], Step [896/1893], Loss: 3.1413\n","Epoch [23/50], Step [1024/1893], Loss: 4.8589\n","Epoch [23/50], Step [1152/1893], Loss: 2.1809\n","Epoch [23/50], Step [1280/1893], Loss: 3.0446\n","Epoch [23/50], Step [1408/1893], Loss: 5.2609\n","Epoch [23/50], Step [1536/1893], Loss: 3.0606\n","Epoch [23/50], Step [1664/1893], Loss: 2.9997\n","Epoch [23/50], Step [1792/1893], Loss: 3.0629\n","Epoch [24/50], Step [128/1893], Loss: 4.7583\n","Epoch [24/50], Step [256/1893], Loss: 3.8576\n","Epoch [24/50], Step [384/1893], Loss: 2.9973\n","Epoch [24/50], Step [512/1893], Loss: 2.7725\n","Epoch [24/50], Step [640/1893], Loss: 5.0277\n","Epoch [24/50], Step [768/1893], Loss: 3.6160\n","Epoch [24/50], Step [896/1893], Loss: 2.9645\n","Epoch [24/50], Step [1024/1893], Loss: 5.2345\n","Epoch [24/50], Step [1152/1893], Loss: 2.0794\n","Epoch [24/50], Step [1280/1893], Loss: 2.8661\n","Epoch [24/50], Step [1408/1893], Loss: 3.4549\n","Epoch [24/50], Step [1536/1893], Loss: 3.5178\n","Epoch [24/50], Step [1664/1893], Loss: 3.9694\n","Epoch [24/50], Step [1792/1893], Loss: 4.1435\n","Epoch [25/50], Step [128/1893], Loss: 3.6535\n","Epoch [25/50], Step [256/1893], Loss: 4.1439\n","Epoch [25/50], Step [384/1893], Loss: 4.5604\n","Epoch [25/50], Step [512/1893], Loss: 3.8653\n","Epoch [25/50], Step [640/1893], Loss: 2.6220\n","Epoch [25/50], Step [768/1893], Loss: 2.5240\n","Epoch [25/50], Step [896/1893], Loss: 3.6606\n","Epoch [25/50], Step [1024/1893], Loss: 3.5438\n","Epoch [25/50], Step [1152/1893], Loss: 2.4716\n","Epoch [25/50], Step [1280/1893], Loss: 3.4895\n","Epoch [25/50], Step [1408/1893], Loss: 3.4536\n","Epoch [25/50], Step [1536/1893], Loss: 2.2086\n","Epoch [25/50], Step [1664/1893], Loss: 3.6734\n","Epoch [25/50], Step [1792/1893], Loss: 4.4472\n","Epoch [26/50], Step [128/1893], Loss: 3.2550\n","Epoch [26/50], Step [256/1893], Loss: 2.5271\n","Epoch [26/50], Step [384/1893], Loss: 3.4752\n","Epoch [26/50], Step [512/1893], Loss: 4.2193\n","Epoch [26/50], Step [640/1893], Loss: 3.3256\n","Epoch [26/50], Step [768/1893], Loss: 2.1690\n","Epoch [26/50], Step [896/1893], Loss: 2.5212\n","Epoch [26/50], Step [1024/1893], Loss: 3.9090\n","Epoch [26/50], Step [1152/1893], Loss: 2.8665\n","Epoch [26/50], Step [1280/1893], Loss: 2.1432\n","Epoch [26/50], Step [1408/1893], Loss: 3.0658\n","Epoch [26/50], Step [1536/1893], Loss: 2.5047\n","Epoch [26/50], Step [1664/1893], Loss: 2.8901\n","Epoch [26/50], Step [1792/1893], Loss: 2.7364\n","Epoch [27/50], Step [128/1893], Loss: 2.9198\n","Epoch [27/50], Step [256/1893], Loss: 1.8317\n","Epoch [27/50], Step [384/1893], Loss: 2.5300\n","Epoch [27/50], Step [512/1893], Loss: 2.5860\n","Epoch [27/50], Step [640/1893], Loss: 2.4285\n","Epoch [27/50], Step [768/1893], Loss: 2.2652\n","Epoch [27/50], Step [896/1893], Loss: 1.7837\n","Epoch [27/50], Step [1024/1893], Loss: 2.0007\n","Epoch [27/50], Step [1152/1893], Loss: 1.7287\n","Epoch [27/50], Step [1280/1893], Loss: 2.3694\n","Epoch [27/50], Step [1408/1893], Loss: 2.4618\n","Epoch [27/50], Step [1536/1893], Loss: 1.6475\n","Epoch [27/50], Step [1664/1893], Loss: 2.4535\n","Epoch [27/50], Step [1792/1893], Loss: 2.3173\n","Epoch [28/50], Step [128/1893], Loss: 2.0727\n","Epoch [28/50], Step [256/1893], Loss: 1.4664\n","Epoch [28/50], Step [384/1893], Loss: 1.7933\n","Epoch [28/50], Step [512/1893], Loss: 1.6811\n","Epoch [28/50], Step [640/1893], Loss: 2.1516\n","Epoch [28/50], Step [768/1893], Loss: 1.7294\n","Epoch [28/50], Step [896/1893], Loss: 1.6250\n","Epoch [28/50], Step [1024/1893], Loss: 2.3679\n","Epoch [28/50], Step [1152/1893], Loss: 1.3149\n","Epoch [28/50], Step [1280/1893], Loss: 1.6026\n","Epoch [28/50], Step [1408/1893], Loss: 2.1382\n","Epoch [28/50], Step [1536/1893], Loss: 1.5363\n","Epoch [28/50], Step [1664/1893], Loss: 1.9929\n","Epoch [28/50], Step [1792/1893], Loss: 1.8081\n","Epoch [29/50], Step [128/1893], Loss: 2.1821\n","Epoch [29/50], Step [256/1893], Loss: 2.1789\n","Epoch [29/50], Step [384/1893], Loss: 2.0386\n","Epoch [29/50], Step [512/1893], Loss: 1.2952\n","Epoch [29/50], Step [640/1893], Loss: 1.6350\n","Epoch [29/50], Step [768/1893], Loss: 1.6318\n","Epoch [29/50], Step [896/1893], Loss: 1.5635\n","Epoch [29/50], Step [1024/1893], Loss: 1.8679\n","Epoch [29/50], Step [1152/1893], Loss: 1.8414\n","Epoch [29/50], Step [1280/1893], Loss: 1.8827\n","Epoch [29/50], Step [1408/1893], Loss: 1.5514\n","Epoch [29/50], Step [1536/1893], Loss: 1.6208\n","Epoch [29/50], Step [1664/1893], Loss: 2.6584\n","Epoch [29/50], Step [1792/1893], Loss: 1.8636\n","Epoch [30/50], Step [128/1893], Loss: 1.5302\n","Epoch [30/50], Step [256/1893], Loss: 1.7535\n","Epoch [30/50], Step [384/1893], Loss: 2.8093\n","Epoch [30/50], Step [512/1893], Loss: 1.2999\n","Epoch [30/50], Step [640/1893], Loss: 1.3406\n","Epoch [30/50], Step [768/1893], Loss: 2.0535\n","Epoch [30/50], Step [896/1893], Loss: 1.6791\n","Epoch [30/50], Step [1024/1893], Loss: 1.4223\n","Epoch [30/50], Step [1152/1893], Loss: 1.3026\n","Epoch [30/50], Step [1280/1893], Loss: 2.0333\n","Epoch [30/50], Step [1408/1893], Loss: 1.8259\n","Epoch [30/50], Step [1536/1893], Loss: 1.4515\n","Epoch [30/50], Step [1664/1893], Loss: 1.9337\n","Epoch [30/50], Step [1792/1893], Loss: 3.6232\n","Epoch [31/50], Step [128/1893], Loss: 2.1113\n","Epoch [31/50], Step [256/1893], Loss: 1.3878\n","Epoch [31/50], Step [384/1893], Loss: 2.3930\n","Epoch [31/50], Step [512/1893], Loss: 3.7394\n","Epoch [31/50], Step [640/1893], Loss: 2.7549\n","Epoch [31/50], Step [768/1893], Loss: 1.3628\n","Epoch [31/50], Step [896/1893], Loss: 2.6721\n","Epoch [31/50], Step [1024/1893], Loss: 3.7379\n","Epoch [31/50], Step [1152/1893], Loss: 2.1603\n","Epoch [31/50], Step [1280/1893], Loss: 1.5581\n","Epoch [31/50], Step [1408/1893], Loss: 2.5026\n","Epoch [31/50], Step [1536/1893], Loss: 2.3143\n","Epoch [31/50], Step [1664/1893], Loss: 1.9741\n","Epoch [31/50], Step [1792/1893], Loss: 1.3985\n","Epoch [32/50], Step [128/1893], Loss: 2.0514\n","Epoch [32/50], Step [256/1893], Loss: 1.8138\n","Epoch [32/50], Step [384/1893], Loss: 1.6609\n","Epoch [32/50], Step [512/1893], Loss: 1.3489\n","Epoch [32/50], Step [640/1893], Loss: 2.0187\n","Epoch [32/50], Step [768/1893], Loss: 1.7882\n","Epoch [32/50], Step [896/1893], Loss: 1.3904\n","Epoch [32/50], Step [1024/1893], Loss: 1.7365\n","Epoch [32/50], Step [1152/1893], Loss: 1.6033\n","Epoch [32/50], Step [1280/1893], Loss: 2.3983\n","Epoch [32/50], Step [1408/1893], Loss: 2.0358\n","Epoch [32/50], Step [1536/1893], Loss: 1.1315\n","Epoch [32/50], Step [1664/1893], Loss: 1.4067\n","Epoch [32/50], Step [1792/1893], Loss: 1.2170\n","Epoch [33/50], Step [128/1893], Loss: 1.4898\n","Epoch [33/50], Step [256/1893], Loss: 1.0703\n","Epoch [33/50], Step [384/1893], Loss: 1.1377\n","Epoch [33/50], Step [512/1893], Loss: 0.9795\n","Epoch [33/50], Step [640/1893], Loss: 0.9318\n","Epoch [33/50], Step [768/1893], Loss: 0.8574\n","Epoch [33/50], Step [896/1893], Loss: 0.7171\n","Epoch [33/50], Step [1024/1893], Loss: 1.0812\n","Epoch [33/50], Step [1152/1893], Loss: 0.8469\n","Epoch [33/50], Step [1280/1893], Loss: 1.0700\n","Epoch [33/50], Step [1408/1893], Loss: 1.2251\n","Epoch [33/50], Step [1536/1893], Loss: 0.7976\n","Epoch [33/50], Step [1664/1893], Loss: 0.8523\n","Epoch [33/50], Step [1792/1893], Loss: 0.8024\n","Epoch [34/50], Step [128/1893], Loss: 0.9867\n","Epoch [34/50], Step [256/1893], Loss: 0.6022\n","Epoch [34/50], Step [384/1893], Loss: 0.7538\n","Epoch [34/50], Step [512/1893], Loss: 0.7225\n","Epoch [34/50], Step [640/1893], Loss: 1.1934\n","Epoch [34/50], Step [768/1893], Loss: 1.0492\n","Epoch [34/50], Step [896/1893], Loss: 0.5976\n","Epoch [34/50], Step [1024/1893], Loss: 1.0634\n","Epoch [34/50], Step [1152/1893], Loss: 0.7392\n","Epoch [34/50], Step [1280/1893], Loss: 0.9084\n","Epoch [34/50], Step [1408/1893], Loss: 0.8704\n","Epoch [34/50], Step [1536/1893], Loss: 0.7244\n","Epoch [34/50], Step [1664/1893], Loss: 0.9404\n","Epoch [34/50], Step [1792/1893], Loss: 0.9112\n","Epoch [35/50], Step [128/1893], Loss: 1.0477\n","Epoch [35/50], Step [256/1893], Loss: 0.6318\n","Epoch [35/50], Step [384/1893], Loss: 0.7536\n","Epoch [35/50], Step [512/1893], Loss: 0.5868\n","Epoch [35/50], Step [640/1893], Loss: 0.7012\n","Epoch [35/50], Step [768/1893], Loss: 0.7204\n","Epoch [35/50], Step [896/1893], Loss: 0.5913\n","Epoch [35/50], Step [1024/1893], Loss: 0.8069\n","Epoch [35/50], Step [1152/1893], Loss: 0.7277\n","Epoch [35/50], Step [1280/1893], Loss: 0.7844\n","Epoch [35/50], Step [1408/1893], Loss: 0.8608\n","Epoch [35/50], Step [1536/1893], Loss: 0.6005\n","Epoch [35/50], Step [1664/1893], Loss: 0.7342\n","Epoch [35/50], Step [1792/1893], Loss: 0.6028\n","Epoch [36/50], Step [128/1893], Loss: 0.8281\n","Epoch [36/50], Step [256/1893], Loss: 0.5955\n","Epoch [36/50], Step [384/1893], Loss: 0.7855\n","Epoch [36/50], Step [512/1893], Loss: 0.7098\n","Epoch [36/50], Step [640/1893], Loss: 0.5830\n","Epoch [36/50], Step [768/1893], Loss: 0.4768\n","Epoch [36/50], Step [896/1893], Loss: 0.4260\n","Epoch [36/50], Step [1024/1893], Loss: 0.6676\n","Epoch [36/50], Step [1152/1893], Loss: 0.7562\n","Epoch [36/50], Step [1280/1893], Loss: 0.8070\n","Epoch [36/50], Step [1408/1893], Loss: 0.8585\n","Epoch [36/50], Step [1536/1893], Loss: 0.6017\n","Epoch [36/50], Step [1664/1893], Loss: 0.7370\n","Epoch [36/50], Step [1792/1893], Loss: 0.5927\n","Epoch [37/50], Step [128/1893], Loss: 0.7087\n","Epoch [37/50], Step [256/1893], Loss: 0.5738\n","Epoch [37/50], Step [384/1893], Loss: 0.7028\n","Epoch [37/50], Step [512/1893], Loss: 0.7332\n","Epoch [37/50], Step [640/1893], Loss: 0.8548\n","Epoch [37/50], Step [768/1893], Loss: 0.8963\n","Epoch [37/50], Step [896/1893], Loss: 0.7487\n","Epoch [37/50], Step [1024/1893], Loss: 0.5360\n"]}]},{"cell_type":"markdown","source":["# Run"],"metadata":{"id":"qppsfyXPMtBo"}},{"cell_type":"code","source":["# use GPU \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wwponmNbbgcv","executionInfo":{"status":"ok","timestamp":1669883101215,"user_tz":480,"elapsed":399,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"89fb23fe-5070-43d6-a462-61bf8ba9b807"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["# Hyperparameters\n","BATCH_SIZE = 32\n","LEARNING_RATE = 0.001\n","NUM_EPOCHS = 50\n","WEIGHT_DECAY = 1e-3"],"metadata":{"id":"21GGDl7VnORt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Preparing the dataloader')\n","df = dhsid_df.sample(frac=1) # shuffle dataset \n","train_df, val_df, test_df = split_train_val_test(df, 2017, 2017, 2018)\n","\n","train_imgs = DHSIDDataset(train_df)\n","test_imgs = DHSIDDataset(test_df)\n","train_loader = DataLoader(train_imgs, batch_size=1, num_workers=2) # always set batch_size = 1 here \n","test_loader = DataLoader(test_imgs, batch_size=1, num_workers=2)\n","\n","model = SatelliteStreetModel('resnet18', 'resnet18') # resnet18 is the best model for satellite model \n","criterion = torch.nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3trJVAaSfuJh","executionInfo":{"status":"ok","timestamp":1669882957940,"user_tz":480,"elapsed":867,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"a38f5cf7-bbb1-48f0-b226-47f9e7207f36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing the dataloader\n"]}]},{"cell_type":"code","source":["print(len(train_imgs), len(test_imgs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1MOXZAbfj-Y","executionInfo":{"status":"ok","timestamp":1669882958980,"user_tz":480,"elapsed":20,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"51e7ce0b-2cb9-4bb7-ff77-c3f980d71b95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1235 223\n"]}]},{"cell_type":"code","source":["train_model(model, train_loader, criterion, optimizer, NUM_EPOCHS, device, BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"YhmJO2-QAz2I","executionInfo":{"status":"error","timestamp":1669882967461,"user_tz":480,"elapsed":7842,"user":{"displayName":"ALDA NAOMI","userId":"01061387583040321032"}},"outputId":"a017a01d-b92d-44d4-f884-483765e9e78b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-109-ab99890ef2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-76-d45b3df67029>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device, batch_size, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mstreet_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstreet_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreet_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# print(output, targets[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-71-2cf1cc0e891b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sat_x, street_x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreet_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msatellite_fv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msatellite_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msat_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msatellite_fv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msatellite_fv\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(satellite_fv.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 453\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}]},{"cell_type":"markdown","source":["# Evaluate"],"metadata":{"id":"541EV6EvBTvU"}},{"cell_type":"code","source":["def evaluate(model, device, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    total = 0\n","    y_true = np.array([])\n","    y_pred = np.array([])\n","    \n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            total += target.size(0)\n","            output = model(data)\n","            target = target.cpu().detach().numpy().squeeze()\n","            pred = output.cpu().detach().numpy().squeeze()\n","            y_true = np.append(y_true, target)\n","            y_pred = np.append(y_pred, pred)\n","\n","  return y_true, y_pred"],"metadata":{"id":"UzmAIQYkBSqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_preds, y_test = evaluate(test_loader, BATCH_SIZE, N_FEATURES)"],"metadata":{"id":"2KWjDsSmBfBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print('Starting training')\n","# best_r2 = 0.\n","# r2 = -1\n","\n","# for epoch in range(1, NUM_EPOCHS+1):\n","#   train(model, device, train_loader, optimizer, criterion, epoch)\n","#   r2, y_true, y_pred = test(model, device, test_loader, criterion, epoch)\n","#   if r2 >= best_r2:\n","#     best_r2 = r2\n","#     torch.save(model.state_dict(), SAVE_NAME + \"/resnet18_model\")\n","#     logging.info(\"\\nSaved model with R2: {:.4f}\\n\".format(best_r2))\n","        \n","#     logging.info(\"\\nBest R2: {:.4f}\\n\".format(best_r2))\n","#     print(\"\\nBest R2: {:.4f}\\n\".format(best_r2))"],"metadata":{"id":"9YJy9-B3f0eu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_metrics(pred, actual, verbose=True):\n","    result_metrics = {'mae' : mean_absolute_error(pred, actual),\n","                      'mape' : mean_absolute_percentage_error(pred, actual),\n","                      'mse' : mean_squared_error(pred, actual), \n","                      'rmse' : mean_squared_error(pred, actual) ** 0.5\n","                      }\n","    \n","    if verbose:\n","      print(\"Mean Absolute Error:       \", result_metrics[\"mae\"])\n","      print(\"Mean Absolute Percentage Error:       \", result_metrics[\"mape\"])\n","      print(\"Mean Squared Error:   \", result_metrics[\"mse\"])\n","      print(\"Root Mean Squared Error:   \", result_metrics[\"rmse\"])\n","      \n","    return result_metrics"],"metadata":{"id":"vR7t-FcVfzFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = calculate_metrics(y_pred, y_true)"],"metadata":{"id":"PggG1oHRh7hb"},"execution_count":null,"outputs":[]}]}